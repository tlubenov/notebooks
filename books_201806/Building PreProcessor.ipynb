{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys, h5py, glob, time\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252.41098427772522\n"
     ]
    }
   ],
   "source": [
    "masks_path = '../bldgs_masks/*_mask.png'\n",
    "\n",
    "masks_800 = []\n",
    "masks_1200 = []\n",
    "\n",
    "hdf5_mask_path = '../masks.hdf5'\n",
    "files = glob.glob(masks_path)\n",
    "\n",
    "width, height = 0, 0\n",
    "\n",
    "beg = time.time()\n",
    "for mask in files:\n",
    "    image = Image.open(mask)\n",
    "#    image.load()\n",
    "    width, height = image.size\n",
    "    if width == 800:\n",
    "        masks_800.append(mask)\n",
    "    \n",
    "    if width == 1200:\n",
    "        masks_1200.append(mask)\n",
    "#    print(width, height)\n",
    "end = time.time()\n",
    "coster = end - beg\n",
    "print(coster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17941 7035\n"
     ]
    }
   ],
   "source": [
    "print(len(masks_800), len(masks_1200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hdf5_mask_path_1200 = '../masks_1200.hdf5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_800_shape = (len(masks_800), 800, 968, 3)\n",
    "mask_1200_shape = (len(masks_1200), 1200, 968, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17941, 800, 968, 3) (7035, 1200, 968, 3)\n"
     ]
    }
   ],
   "source": [
    "print(mask_800_shape, mask_1200_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"bldgs_masks_800\": shape (17941, 800, 968, 3), type \"|i1\">"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hdf5_mask_file_800 = h5py.File(hdf5_mask_path_800, mode='w')\n",
    "hdf5_mask_file_800.create_dataset(\"bldgs_masks_800\", mask_800_shape, np.int8)\n",
    "hdf5_mask_file_800.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hdf5_mask_file_1200 = h5py.File(hdf5_mask_path_1200, mode='w')\n",
    "hdf5_mask_file_1200.create_dataset(\"bldgs_masks_1200\", mask_1200_shape, np.int8)\n",
    "hdf5_mask_file_1200.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_mask_file_800.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 1000/17941\n",
      "Train data: 2000/17941\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-597831b86a08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# if the data order is Theano, axis orders should change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# save the image and calculate the mean so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mhdf5_mask_file_800\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bldgs_masks_800\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m#mean += img / float(len(train_labels))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/ai_imagery/py36_venv/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#17941\n",
    "hdf5_mask_path_800 = '../masks_800.hdf5'\n",
    "\n",
    "mask_800_shape = (len(masks_800), 968, 800, 3)\n",
    "hdf5_mask_file_800 = h5py.File(hdf5_mask_path_800, mode='w')\n",
    "hdf5_mask_file_800.create_dataset(\"bldgs_masks_800\", mask_800_shape, np.int8)\n",
    "\n",
    "# a numpy array to save the mean of the images\n",
    "#mean = np.zeros(masks_800[1:], np.float32)\n",
    "\n",
    "# loop over train addresses\n",
    "for i in range(len(masks_800)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Train data: {}/{}'.format(i, len(masks_800)))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "#    addr = train_addrs[i]\n",
    "    image = masks_800[i]\n",
    "    img = cv2.imread(image)\n",
    "#    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # add any image pre-processing here\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    # save the image and calculate the mean so far\n",
    "    hdf5_mask_file_800[\"bldgs_masks_800\"][i, ...] = img[None]\n",
    "    #mean += img / float(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "a = platform.python_implementation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CPython'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object getFile at 0x7f65e450f888>\n",
      "<generator object getFile at 0x7f65e450f888>\n",
      "<generator object getFile at 0x7f65e450f888>\n",
      "<generator object getFile at 0x7f65e450f888>\n",
      "<generator object getFile at 0x7f65e450f888>\n",
      "<generator object getFile at 0x7f65e450f888>\n",
      "<generator object getFile at 0x7f65e450f888>\n"
     ]
    }
   ],
   "source": [
    "def getFile(list_of_files):\n",
    "    \n",
    "    \n",
    "    yield filer\n",
    "\n",
    "\n",
    "asd = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n",
    "\n",
    "for a in asd:\n",
    "    print(getFile(asd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a numpy array to save the mean of the images\n",
    "mean = np.zeros(train_shape[1:], np.float32)\n",
    "\n",
    "# loop over train addresses\n",
    "for i in range(len(train_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print 'Train data: {}/{}'.format(i, len(train_addrs))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = train_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # add any image pre-processing here\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "    # save the image and calculate the mean so far\n",
    "    hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "    mean += img / float(len(train_labels))\n",
    "\n",
    "# loop over validation addresses\n",
    "for i in range(len(val_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print 'Validation data: {}/{}'.format(i, len(val_addrs))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = val_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # add any image pre-processing here\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "    # save the image\n",
    "    hdf5_file[\"val_img\"][i, ...] = img[None]\n",
    "\n",
    "# loop over test addresses\n",
    "for i in range(len(test_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print 'Test data: {}/{}'.format(i, len(test_addrs))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = test_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # add any image pre-processing here\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "    # save the image\n",
    "    hdf5_file[\"test_img\"][i, ...] = img[None]\n",
    "\n",
    "# save the mean and close the hdf5 file\n",
    "hdf5_file[\"train_mean\"][...] = mean\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
